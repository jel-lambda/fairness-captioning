{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop and combine images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../\n",
    "!git clone https://github.com/junleen/RainNet\n",
    "%cd RainNet\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from util.config import cfg as test_cfg\n",
    "from data.test_dataset import TestDataset\n",
    "from util import util\n",
    "from models.networks import RainNet\n",
    "from models.normalize import RAIN\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(cfg):\n",
    "    net = RainNet(input_nc=cfg.input_nc, \n",
    "                output_nc=cfg.output_nc, \n",
    "                ngf=cfg.ngf, \n",
    "                norm_layer=RAIN, \n",
    "                use_dropout=not cfg.no_dropout)\n",
    "    \n",
    "    load_path = os.path.join(cfg.checkpoints_dir, cfg.name, 'net_G.pth')\n",
    "    if not os.path.exists(load_path):\n",
    "        print('%s not exists. Please check the file'%(load_path))\n",
    "    print(f'loading the model from {load_path}')\n",
    "    state_dict = torch.load(load_path)\n",
    "    util.copy_state_dict(net.state_dict(), state_dict)\n",
    "    # net.load_state_dict(state_dict)\n",
    "    return net\n",
    "\n",
    "def save_img(path, img):\n",
    "    os.makedirs(os.path.split(path)[0], exist_ok=True)\n",
    "    io.imsave(path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "rainnet = load_network(test_cfg).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/home/cvmlserver/Seohyeon/v-coco/'\n",
    "\n",
    "padded_folder = os.path.join(base, 'data/padded_masks/')\n",
    "input_folder = os.path.join(base, 'data/combined/')\n",
    "final_folder = os.path.join(base, 'data/final/')\n",
    "\n",
    "bg_names = os.listdir(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comb_path = [base+'data/combined/'+bg_class+'/'+comb for bg_class in bg_names for comb in os.listdir(os.path.join(input_folder, bg_class)) if comb.endswith('.png')]\n",
    "mask_path = [base+'data/padded_masks/'+bg_class+'/'+file for bg_class in bg_names for file in os.listdir(os.path.join(padded_folder, bg_class))]\n",
    "print(mask_path[:3])\n",
    "real_path = comb_path\n",
    "print(len(comb_path))\n",
    "print(len(mask_path))\n",
    "\n",
    "testdata = TestDataset(foreground_paths=comb_path, mask_paths=mask_path, background_paths=real_path, load_size=1024)\n",
    "print(testdata)\n",
    "# cv2.imwrite(os.path.join(final_folder, bg_class, image_name), testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_times = 0 # adjust the foreground image by several times\n",
    "import cv2\n",
    "for idx in range(len(testdata)):\n",
    "    sample = testdata[idx]\n",
    "    # unsqueeze the data to shape of (1, channel, H, W)\n",
    "    comp = sample['comp'].unsqueeze(0).to(device)\n",
    "    mask = sample['mask'].unsqueeze(0).to(device) # if you want to adjust the background to be compatible with the foreground, then add the following command\n",
    "    # mask = 1 - mask\n",
    "    real = sample['real'].unsqueeze(0).to(device) # if the real_path is not given, then return composite image by sample['real']\n",
    "    img_path = sample['img_path']\n",
    "    pred = rainnet.processImage(comp, mask, real)\n",
    "    for i in range(repeat_times):\n",
    "        pred = rainnet.processImage(pred, mask, pred)\n",
    "        \n",
    "    # tensor2image\n",
    "    person_image = cv2.imread(img_path)\n",
    "    pred_rgb = util.tensor2im(pred[0:1])\n",
    "    w, h, _ = person_image.shape\n",
    "    pred_rgb = cv2.resize(pred_rgb, (h, w))\n",
    "    \n",
    "    # comp_rgb = util.tensor2im(comp[:1])\n",
    "    # mask_rgb = util.tensor2im(mask[:1])\n",
    "    # real_rgb = util.tensor2im(real[:1])\n",
    "    if not os.path.exists(final_folder+img_path.split('/')[-2]):\n",
    "        os.mkdir(final_folder+img_path.split('/')[-2])\n",
    "    print(final_folder+img_path.split('/')[-2]+'/'+img_path.split('/')[-1])\n",
    "    print(pred_rgb.shape)\n",
    "    save_img(final_folder+img_path.split('/')[-2]+'/'+img_path.split('/')[-1], pred_rgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('11775-hw2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "b157589e2ede00d340fed454223ce98f3e66982c0431b5c5286cc0a4d3cc5a4f"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "09f94152c9560a9262e19909104123c27996423b8d9cefbf1cc31600487b030b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
