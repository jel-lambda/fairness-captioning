{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3t-jsyrtl7w"
   },
   "source": [
    "## MODNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEwiokUgkSDO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# clone the repository\n",
    "if not os.path.exists('MODNet'):\n",
    "  !git clone https://github.com/ZHKKKe/MODNet\n",
    "\n",
    "%cd MODNet/\n",
    "\n",
    "# dowload the pre-trained ckpt for image matting\n",
    "pretrained_ckpt = 'pretrained/modnet_photographic_portrait_matting.ckpt'\n",
    "if not os.path.exists(pretrained_ckpt):\n",
    "  !gdown --id 1mcr7ALciuAsHCpLnrtG_eop5-EYhbCmz \\\n",
    "          -O pretrained/modnet_photographic_portrait_matting.ckpt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwMfEIiwu5VB"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJaRhVYdfxNt"
   },
   "source": [
    "<p align=\"justify\">Run the following command for alpha matte prediction:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fi1jtFug-Nvh"
   },
   "outputs": [],
   "source": [
    "!python -m demo.image_matting.colab.inference \\\n",
    "        --input-path data/original \\\n",
    "        --output-path data/masks \\\n",
    "        --ckpt-path ./pretrained/modnet_photographic_portrait_matting.ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2  \n",
    "\n",
    "# extract backgrounds from input using mask\n",
    "def combined_display(image, matte, image_name):\n",
    "    w, h, c = image.shape\n",
    "    rw, rh = 800, int(h * 800 / (3 * w))\n",
    "    foreground = cv2.bitwise_and(image, image, mask=matte)\n",
    "    (thresh, matte) = cv2.threshold(matte, w, h, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    thresh = 255 - thresh\n",
    "    matte = cv2.threshold(matte, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    foreground = cv2.bitwise_and(image, image, mask=matte)\n",
    "\n",
    "    cv2.imwrite('../data/person_dataset/'+image_name, foreground)\n",
    "\n",
    "input_folder = '../data/original/'\n",
    "output_folder = '../data/masks/'\n",
    "# visualize all images\n",
    "image_names = os.listdir(input_folder)\n",
    "\n",
    "for image_name in image_names:\n",
    "    matte_name = image_name.split('.')[0] + '.png'\n",
    "    image = cv2.imread(os.path.join(input_folder, image_name))\n",
    "    matte = cv2.imread(os.path.join(output_folder, matte_name),cv2.IMREAD_GRAYSCALE)\n",
    "    #  matte = cv2.cvtColor(matte, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    \n",
    "    combined_display(image, matte, matte_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfDKNQNeeLhx"
   },
   "source": [
    "## Download Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqNdGeIf1cc8"
   },
   "source": [
    "<p align=\"justify\">Download the Zip package of predicted alpha mattes:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6aqVu631k01"
   },
   "outputs": [],
   "source": [
    "zip_filename = 'matte.zip'\n",
    "import os \n",
    "\n",
    "if os.path.exists(zip_filename):\n",
    "  os.remove(zip_filename)\n",
    "\n",
    "os.system(f\"zip -r -j {zip_filename} {output_folder}/*\")\n",
    "files.download(zip_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('11775-hw2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09f94152c9560a9262e19909104123c27996423b8d9cefbf1cc31600487b030b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
