{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop and combine images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# from util import util\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# change this path to your own path\n",
    "base = '/home/cvmlserver/Seohyeon/v-coco/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop foreground image with object area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the image folder\n",
    "input_folder = os.path.join(base, 'data/person_dataset/')\n",
    "mask_folder = os.path.join(base, 'data/masks/')\n",
    "bg_folder = os.path.join(base, 'data/backgrounds/')\n",
    "output_folder = os.path.join(base, 'data/')\n",
    "\n",
    "female_images = os.listdir(os.path.join(input_folder, 'Female'))\n",
    "male_images = os.listdir(os.path.join(input_folder, 'Male'))\n",
    "bg_classes = os.listdir(bg_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, mask, image_name):\n",
    "    black = np.logical_and(mask[:,:,0] != 0, np.logical_and(mask[:,:,1] != 0, mask[:,:,2] != 0))\n",
    "    y, x = np.where(black)\n",
    "    minx = np.min(x)\n",
    "    miny = np.min(y)\n",
    "    maxx = np.max(x)\n",
    "    maxy = np.max(y) \n",
    "    img_trim = image[miny:maxy, minx:maxx]\n",
    "    mask_trim = mask[miny:maxy, minx:maxx]\n",
    "    cv2.imwrite(os.path.join(output_folder, 'cropped_images', image_name), img_trim)\n",
    "    cv2.imwrite(os.path.join(output_folder, 'cropped_masks', image_name), mask_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(female_images)):\n",
    "    female_image = cv2.imread(os.path.join(input_folder, 'Female', female_images[i]),cv2.IMREAD_UNCHANGED)\n",
    "    male_image = cv2.imread(os.path.join(input_folder, 'Male', male_images[i]),cv2.IMREAD_UNCHANGED)\n",
    "    female_mask = cv2.imread(os.path.join(mask_folder, female_images[i]), cv2.COLOR_RGB2GRAY)\n",
    "    male_mask = cv2.imread(os.path.join(mask_folder, male_images[i]), cv2.COLOR_RGB2GRAY)\n",
    "    crop_image(female_image, female_mask, female_images[i])\n",
    "    crop_image(male_image, male_mask, male_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine image with area information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_image(bg_name, image, mask, background, output_folder, image_name, loc):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
    "    h, w = image.shape[:2]\n",
    "    height, width = background.shape[:2]\n",
    "    \n",
    "    if h > w:\n",
    "        new_width = w+300\n",
    "        new_height = int(height * new_width / width)\n",
    "        if new_height < h:\n",
    "            new_height = h+100\n",
    "            new_width = int(width * new_height / height)\n",
    "    else:\n",
    "        new_height = h+300\n",
    "        new_width  = int(new_height * width / height)\n",
    "        if new_width < w:\n",
    "            new_width = w+100\n",
    "            new_height = int(new_width * height / width)\n",
    "    background = cv2.resize(background, (int(new_width), int(new_height)))\n",
    "    \n",
    "    mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    if loc == 'left':\n",
    "        roi = background[new_height-h:, 0:w]\n",
    "        masked_bg = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "        added = masked_bg + image\n",
    "        background[new_height-h:, 0:w] = added\n",
    "        \n",
    "    elif loc == 'right':\n",
    "        roi = background[new_height-h:, int(new_width-w):int(new_width)]\n",
    "        masked_bg = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "        added = masked_bg + image\n",
    "        background[new_height-h:, int(new_width-w):int(new_width)] = added\n",
    "    \n",
    "    elif loc == 'center':\n",
    "        roi = background[new_height-h:, int(new_width/2-w/2):int(new_width/2+w/2)]\n",
    "        masked_bg = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "        added = masked_bg + image\n",
    "        background[new_height-h:, int(new_width/2-w/2):int(new_width/2+w/2)] = added\n",
    "\n",
    "    else:\n",
    "        image = image[:int(h/3)*2, :]\n",
    "        mask = mask[:int(h/3)*2, :]\n",
    "        roi = background[new_height-image.shape[:2][0]:, int(new_width/2-w/2):int(new_width/2+w/2)]\n",
    "        masked_bg = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "        added = masked_bg + image\n",
    "        background[new_height-image.shape[:2][0]:, int(new_width/2-w/2):int(new_width/2+w/2)] = added\n",
    "\n",
    "    if not os.path.exists(output_folder + bg_name):\n",
    "        os.mkdir(os.path.join(output_folder, bg_name))\n",
    "\n",
    "    cv2.imwrite(os.path.join(output_folder, bg_name, image_name), background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = os.path.join(base, 'data/cropped_images/')\n",
    "mask_folder = os.path.join(base, 'data/cropped_masks/')\n",
    "bg_folder = os.path.join(base, 'data/backgrounds/')\n",
    "output_folder = os.path.join(base, 'data/combined/')\n",
    "\n",
    "with open(os.path.join(base, 'data/annotations/raw/person_image_annotation.json'), 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "person_images = os.listdir(input_folder)\n",
    "bg_classes = os.listdir(bg_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bg_class in bg_classes:\n",
    "    bg_images = os.listdir(os.path.join(bg_folder, bg_class))\n",
    "    for image in bg_images:\n",
    "        if not image.endswith('.jpg'):\n",
    "            pass\n",
    "        for i in range(len(person_images)):\n",
    "            person_image = cv2.imread(os.path.join(input_folder, person_images[i]))\n",
    "            mask = cv2.imread(os.path.join(mask_folder, person_images[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            w, h, c = person_image.shape\n",
    "            \n",
    "            (thresh, mask) = cv2.threshold(mask, w, h, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "            thresh = 255 - thresh\n",
    "            mask = cv2.threshold(mask, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "            bg = cv2.imread(os.path.join(bg_folder, bg_class, image))\n",
    "            loc = data[person_images[i]][0]['cropping_info']\n",
    "            combine_image(image.split('.')[0], person_image, mask, bg, output_folder, person_images[i], loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad to masks to get the same size as the combined images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = os.listdir(mask_folder)\n",
    "padded_folder = os.path.join(base, 'data/padded_masks/')\n",
    "combined_path = os.path.join(base, 'data/combined/')\n",
    "bg_dirs = os.listdir(combined_path)\n",
    "\n",
    "for bg_name in bg_dirs:\n",
    "    comb_images = os.listdir(os.path.join(combined_path, bg_name))\n",
    "    for image in comb_images:\n",
    "        combined_image = cv2.imread(os.path.join(combined_path, bg_name, image))\n",
    "        \n",
    "        try:\n",
    "            combined_image.shape[1]\n",
    "        except AttributeError:\n",
    "            print(\"shape not found\", os.path.join(output_folder, bg_class, image))\n",
    "            continue\n",
    "\n",
    "        # assert not isinstance(combined_image,type(None)), 'image not found'  \n",
    "        mask_image = cv2.imread(os.path.join(mask_folder, image))\n",
    "        old_image_height, old_image_width, channels = mask_image.shape\n",
    "        \n",
    "        new_image_width = combined_image.shape[1]\n",
    "        new_image_height = combined_image.shape[0]\n",
    "\n",
    "        color = (0,0,0)\n",
    "        result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
    "        # compute center offset\n",
    "        x_center = (new_image_width - old_image_width) // 2\n",
    "        y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "        # copy img image into center of result image\n",
    "        result[new_image_height-old_image_height:, \n",
    "            x_center:x_center+old_image_width] = mask_image\n",
    "\n",
    "        # save result\n",
    "        if not os.path.exists(padded_folder + bg_name):\n",
    "            os.mkdir(os.path.join(padded_folder, bg_name))\n",
    "\n",
    "        cv2.imwrite(os.path.join(padded_folder, bg_name, image), result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('11775-hw2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "b157589e2ede00d340fed454223ce98f3e66982c0431b5c5286cc0a4d3cc5a4f"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "09f94152c9560a9262e19909104123c27996423b8d9cefbf1cc31600487b030b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
